"-",as.character(NAO.daily[i,3]),sep=""),format="%Y-%m-%d")
}
NAO.daily <- mutate(as.tibble(NAO.daily), date = make_date(year, month, day))
index <- as.Date(intersect(as.Date(temp_max_Montana[,2]),as.Date(NAO.date)))
nao <- NAO.daily[which(NAO.daily$date %in% index), 4]
nao <- as.vector(nao)
#Montana
x_Montana          <- data.frame("time"=temp_max_Montana[,2],
"nao"=nao,
"d"=season_day,
"temp"=temp_max_Montana[,3])
as.numeric.factor  <- function(x) {as.numeric(levels(x))[x]}
x_Montana[,"temp"] <- as.numeric(x_Montana[,"temp"])
x_Montana[,"time"] <- as.numeric(year(as.POSIXlt(x_Montana[,"time"], format="%Y-%m-%d")))
x_Montana[,"time"] <- (x_Montana[,"time"]-min(x_Montana[,"time"]))/(max(x_Montana[,"time"])-
min(x_Montana[,"time"]))
#Zermatt
x_Zermatt          <- data.frame("time"=temp_max_Zermatt[,2],
"nao"=nao,
"d"=season_day,
"temp"=temp_max_Zermatt[,3])
as.numeric.factor  <- function(x) {as.numeric(levels(x))[x]}
x_Zermatt[,"temp"] <- as.numeric(x_Zermatt[,"temp"])
x_Zermatt[,"time"] <- as.numeric(year(as.POSIXlt(x_Zermatt[,"time"], format="%Y-%m-%d")))
x_Zermatt[,"time"] <- (x_Zermatt[,"time"]-min(x_Zermatt[,"time"]))/(max(x_Zermatt[,"time"])-
min(x_Zermatt[,"time"]))
Z <- data.frame("Montana"=x_Montana[,"temp"] , "Zermatt"=x_Zermatt[,"temp"], "NAO"=x_Zermatt[,"NAO"])
# Scatterplot of Zermatt values against Montana values
plot(Z$Montana, Z$Zermatt, xlab = "Montana Temperature", ylab = "Zermatt Temperature",
main = "Zermatt vs Montana Temperatures")
abline(lm(Z$Zermatt ~ Z$Montana), col = "red")
legend("topright",
legend = "Fitted Regression Line",
col = "red",
lty = 1,
cex = 0.8)
# Scatterplot of Montana values against NAO values
plot(Z$Montana, Z$NAO, xlab = "Montana Temperature", ylab = "NAO Index",
main = "Montana Temperature vs NAO Index")
abline(lm(Z$NAO ~ Z$Montana), col = "red") # Add a linear regression line
legend("topright",
legend = "Fitted Regression",
col = "red",
lty = 1,
cex = 0.8)
cor_Zermatt_Montana <- cor(Z$Zermatt, Z$Montana)
cat("Correlation between Zermatt and Montana Temperatures:", cor_Zermatt_Montana, "\n")
cor.test(Z$Zermatt, Z$Montana)
# Correlation between Montana Temperatures and NAO Index
cor_Montana_NAO <- cor(Z$Montana, Z$NAO)
cat("Correlation between Montana Temperatures and NAO Index:", cor_Montana_NAO, "\n")
# correlation test
cor.test(Z$Montana, Z$NAO) # significant
# Create a data frame for Zermatt vs Montana Temperatures
data_Zermatt_Montana <- data.frame(Zermatt = Z$Zermatt, Montana = Z$Montana)
# Chi Plot - Zermatt vs Montana Temperatures
chiplot(data_Zermatt_Montana, main1 = "Chi Plot - Zermatt vs Montana Temperatures")
# Create a data frame for Montana Temperatures vs NAO Index
data_Montana_NAO <- data.frame(Montana = Z$Montana, NAO = Z$NAO)
# Chi Plot - Montana Temperatures vs NAO Index
chiplot(data_Montana_NAO, main1 = "Chi Plot - Montana Temperatures vs NAO Index")
engie <- read.csv(here::here("data/practical_3/engie.csv"))
veolia <- read.csv(here::here("data/practical_3/veolia.csv"))
# Data cleaning and plot
engie <- engie[-c(4456, 4489), ]
veolia <- veolia[-c(4456, 4489), ]
engie$Adj.Close <- as.numeric(engie$Adj.Close)
veolia$Adj.Close <- as.numeric(veolia$Adj.Close)
par(mfrow = c(1,2))
plot(engie$Adj.Close)
plot(veolia$Adj.Close)
# ADF test to asses the stationarity
adf_engie <- adf.test(engie$Adj.Close) #p-value = 0.4466
adf_veolia <- adf.test(veolia$Adj.Close)#p-value = 0.8228
# Create log return function
calculate_log_returns <- function(stocks) {
log_returns <- -diff(log(stocks))
return(log_returns)
}
# Calculate negative log returns for each index
log_returns_engie <- calculate_log_returns(engie$Adj.Close)
plot(log_returns_engie)
log_returns_veolia <- calculate_log_returns(veolia$Adj.Close)
plot(log_returns_veolia)
plot_engie <- plot_ly(x = engie$Date, y = engie$Adj.Close, type = "scatter", mode = "point", name = "Engie") %>%
layout(title = "Engie")
plot_veolia <- plot_ly(x = veolia$Date, y = veolia$Adj.Close, type = "scatter", mode = "point", name = "Veolia") %>%
layout(title = "Veolia")
combined_plot_2 <- subplot(plot_engie, plot_veolia)
layout(combined_plot_2, title = "Comparison of stock indices")
df_log_returns <- data.frame(log_returns_engie, log_returns_veolia)
# Drawing a scatter plot
par(pty="s")
scatter.smooth(x = log_returns_engie, y = log_returns_veolia, xlab = "Engie negative log returns", ylab = "Veolia negative log returns")
# We compute and show the CDF for both negative log returns
cdf_engie <- ecdf(log_returns_engie)
cdf_veolia <- ecdf(log_returns_veolia)
plot(cdf_engie, col = "red", main = "Empirical Cumulative Distributions")
lines(cdf_veolia, col ="blue")
legend("bottomright", legend = c("Engie", "Veolia"), col = c("red", "blue"), lty = 1)
# Probabilities for cdf_engie and cdf_veoila
u1 <- pobs(log_returns_engie)
u2 <- pobs(log_returns_veolia)
data <- data.frame(engie_prob = u1, veolia_prob = u2)
data_matrix <- as.matrix(data)
pairs.panels(data, method = "kendall")
??pairs.panels
source(here::here("script/setup.R"))
source(here::here("script/setup.R"))
##### Download daily NAO measurements
NAO.daily <- fread('ftp://ftp.cdc.noaa.gov/Public/gbates/teleconn/nao.reanalysis.t10trunc.1948-present.txt')
NAO.daily <- as.matrix(NAO.daily)
colnames(NAO.daily) <- c("year","month","day","NAO")
##### Download temperature data: be sure to work in the correct directory
months <- c(12,1,2) #keep only winter observations
temp_max_Zermatt           <- read_delim(here::here("data/practical_3/daily_maximum_Zermatt/order_107669_data.txt"),
";", escape_double = FALSE, col_types =
cols(time = col_number()),
trim_ws = TRUE, skip = 1)
colnames(temp_max_Zermatt) <- c("station","time","temp")
temp_max_Zermatt           <- temp_max_Zermatt[-1,]
temp_max_Zermatt[,2]       <- as.Date(apply(temp_max_Zermatt[,2],1,as.character),
"%Y%m%d")
temp_max_Montana           <- read_delim(here::here("data/practical_3/daily_maximum_Montana/order_107668_data.txt"),
";", escape_double = FALSE, col_types =
cols(time = col_number()),
trim_ws = TRUE, skip = 1)
colnames(temp_max_Montana) <- c("station","time","temp")
temp_max_Montana           <- temp_max_Montana[-1,]
temp_max_Montana[,2]       <- as.Date(apply(temp_max_Montana[,2],1,as.character),
"%Y%m%d")
###match the dates of the two time series
temp_max_Montana           <- temp_max_Montana[match(as.matrix(temp_max_Zermatt[,2]),
as.matrix(temp_max_Montana[,2])),]
temp_max_Montana           <- as.matrix(temp_max_Montana)
colnames(temp_max_Montana) <- c("station","time","temp")
temp_max_Zermatt           <- as.matrix(temp_max_Zermatt)
colnames(temp_max_Zermatt) <- c("station","time","temp")
###keep only winter dates
temp_max_Montana <- temp_max_Montana[which(month(as.POSIXlt(temp_max_Montana[,"time"],
format="%Y-%m-%d")) %in% months),]
temp_max_Zermatt <- temp_max_Zermatt[which(month(as.POSIXlt(temp_max_Zermatt[,"time"],
format="%Y-%m-%d")) %in% months),]
Date       <- function( length = 0 ){
newDate = numeric( length )
class(newDate) = "Date"
return(newDate)
}
season_day                   <- yday(as.Date(temp_max_Montana[,2]))
season_day[season_day < 61]  <- season_day[season_day < 61] + 31
season_day[season_day > 334] <- season_day[season_day > 334]- 334
NAO.date <- Date(nrow(NAO.daily))
for(i in 1:nrow(NAO.daily)){
NAO.date[i] <- as.Date(paste(as.character(NAO.daily[i,1]),"-",as.character(NAO.daily[i,2]),
"-",as.character(NAO.daily[i,3]),sep=""),format="%Y-%m-%d")
}
NAO.daily <- mutate(as.tibble(NAO.daily), date = make_date(year, month, day))
index <- as.Date(intersect(as.Date(temp_max_Montana[,2]),as.Date(NAO.date)))
nao <- NAO.daily[which(NAO.daily$date %in% index), 4]
nao <- as.vector(nao)
#Montana
x_Montana          <- data.frame("time"=temp_max_Montana[,2],
"nao"=nao,
"d"=season_day,
"temp"=temp_max_Montana[,3])
as.numeric.factor  <- function(x) {as.numeric(levels(x))[x]}
x_Montana[,"temp"] <- as.numeric(x_Montana[,"temp"])
x_Montana[,"time"] <- as.numeric(year(as.POSIXlt(x_Montana[,"time"], format="%Y-%m-%d")))
x_Montana[,"time"] <- (x_Montana[,"time"]-min(x_Montana[,"time"]))/(max(x_Montana[,"time"])-
min(x_Montana[,"time"]))
#Zermatt
x_Zermatt          <- data.frame("time"=temp_max_Zermatt[,2],
"nao"=nao,
"d"=season_day,
"temp"=temp_max_Zermatt[,3])
as.numeric.factor  <- function(x) {as.numeric(levels(x))[x]}
x_Zermatt[,"temp"] <- as.numeric(x_Zermatt[,"temp"])
x_Zermatt[,"time"] <- as.numeric(year(as.POSIXlt(x_Zermatt[,"time"], format="%Y-%m-%d")))
x_Zermatt[,"time"] <- (x_Zermatt[,"time"]-min(x_Zermatt[,"time"]))/(max(x_Zermatt[,"time"])-
min(x_Zermatt[,"time"]))
Z <- data.frame("Montana"=x_Montana[,"temp"] , "Zermatt"=x_Zermatt[,"temp"], "NAO"=x_Zermatt[,"NAO"])
# Scatterplot of Zermatt values against Montana values
plot(Z$Montana, Z$Zermatt, xlab = "Montana Temperature", ylab = "Zermatt Temperature",
main = "Zermatt vs Montana Temperatures")
abline(lm(Z$Zermatt ~ Z$Montana), col = "red")
legend("topright",
legend = "Fitted Regression Line",
col = "red",
lty = 1,
cex = 0.8)
# Scatterplot of Montana values against NAO values
plot(Z$Montana, Z$NAO, xlab = "Montana Temperature", ylab = "NAO Index",
main = "Montana Temperature vs NAO Index")
abline(lm(Z$NAO ~ Z$Montana), col = "red") # Add a linear regression line
legend("topright",
legend = "Fitted Regression",
col = "red",
lty = 1,
cex = 0.8)
cor_Zermatt_Montana <- cor(Z$Zermatt, Z$Montana)
cat("Correlation between Zermatt and Montana Temperatures:", cor_Zermatt_Montana, "\n")
cor.test(Z$Zermatt, Z$Montana)
# Correlation between Montana Temperatures and NAO Index
cor_Montana_NAO <- cor(Z$Montana, Z$NAO)
cat("Correlation between Montana Temperatures and NAO Index:", cor_Montana_NAO, "\n")
# correlation test
cor.test(Z$Montana, Z$NAO) # significant
# Create a data frame for Zermatt vs Montana Temperatures
data_Zermatt_Montana <- data.frame(Zermatt = Z$Zermatt, Montana = Z$Montana)
# Chi Plot - Zermatt vs Montana Temperatures
chiplot(data_Zermatt_Montana, main1 = "Chi Plot - Zermatt vs Montana Temperatures")
# Create a data frame for Montana Temperatures vs NAO Index
data_Montana_NAO <- data.frame(Montana = Z$Montana, NAO = Z$NAO)
# Chi Plot - Montana Temperatures vs NAO Index
chiplot(data_Montana_NAO, main1 = "Chi Plot - Montana Temperatures vs NAO Index")
engie <- read.csv(here::here("data/practical_3/engie.csv"))
veolia <- read.csv(here::here("data/practical_3/veolia.csv"))
# Data cleaning and plot
engie <- engie[-c(4456, 4489), ]
veolia <- veolia[-c(4456, 4489), ]
engie$Adj.Close <- as.numeric(engie$Adj.Close)
veolia$Adj.Close <- as.numeric(veolia$Adj.Close)
par(mfrow = c(1,2))
plot(engie$Adj.Close)
plot(veolia$Adj.Close)
# ADF test to asses the stationarity
adf_engie <- adf.test(engie$Adj.Close) #p-value = 0.4466
adf_veolia <- adf.test(veolia$Adj.Close)#p-value = 0.8228
# Create log return function
calculate_log_returns <- function(stocks) {
log_returns <- -diff(log(stocks))
return(log_returns)
}
# Calculate negative log returns for each index
log_returns_engie <- calculate_log_returns(engie$Adj.Close)
plot(log_returns_engie)
log_returns_veolia <- calculate_log_returns(veolia$Adj.Close)
plot(log_returns_veolia)
plot_engie <- plot_ly(x = engie$Date, y = engie$Adj.Close, type = "scatter", mode = "point", name = "Engie") %>%
layout(title = "Engie")
plot_veolia <- plot_ly(x = veolia$Date, y = veolia$Adj.Close, type = "scatter", mode = "point", name = "Veolia") %>%
layout(title = "Veolia")
combined_plot_2 <- subplot(plot_engie, plot_veolia)
layout(combined_plot_2, title = "Comparison of stock indices")
df_log_returns <- data.frame(log_returns_engie, log_returns_veolia)
# Drawing a scatter plot
par(pty="s")
scatter.smooth(x = log_returns_engie, y = log_returns_veolia, xlab = "Engie negative log returns", ylab = "Veolia negative log returns")
# We compute and show the CDF for both negative log returns
cdf_engie <- ecdf(log_returns_engie)
cdf_veolia <- ecdf(log_returns_veolia)
plot(cdf_engie, col = "red", main = "Empirical Cumulative Distributions")
lines(cdf_veolia, col ="blue")
legend("bottomright", legend = c("Engie", "Veolia"), col = c("red", "blue"), lty = 1)
# Probabilities for cdf_engie and cdf_veoila
u1 <- pobs(log_returns_engie)
u2 <- pobs(log_returns_veolia)
data <- data.frame(engie_prob = u1, veolia_prob = u2)
data_matrix <- as.matrix(data)
pairs.panels(data, method = "kendall")
# Fit Gaussian copula
gaussian_copula <- normalCopula(dim = 2)
fit_gaussian <- fitCopula(gaussian_copula, data, method = "mpl")
# Fit t copula
t_copula <- tCopula(dim = 2, df = 3)
fit_t <- fitCopula(t_copula, data, method = "mpl")
# Fit Gumbel copula
gumbel_copula <- gumbelCopula(dim = 2)
fit_gumbel <- fitCopula(gumbel_copula, data, method = "mpl")
# Fit Clayton copula
clayton_copula <- claytonCopula(dim = 2, param = 2)
fit_clayton <- fitCopula(clayton_copula, data, method = "mpl")
# Calculate AIC values
aic_values <- AIC(fit_gaussian, fit_t, fit_gumbel, fit_clayton)
aic_values
min(aic_values$AIC) ###the t distribution fits the best our data
BiCopSelect(data[,1], data[,2], familyset=NA)
#Compute the tail dependence parameters through BiCopPar2TailDep and lambda functions
BiCopPar2TailDep(family = 2, par = fit_t@copula@parameters[1], par2 = fit_t@copula@parameters[2])
lambda(fit_t@copula)
fitLambda(data_matrix, method = "t", lower.tail = F)
chiplot(df_log_returns)
source(here::here("script/setup.R"))
# Read the Data
venice <- venice90
# Using block maxima approach to have the maximum sea level per year
venice_max <- venice %>%
group_by(year) %>%
summarise(max_sea_level = max(sealevel))
head(venice_max)
plot_ly(venice_max, x = ~year, y = ~max_sea_level, type = 'scatter', mode = 'markers', name = 'Max Value') %>% layout(title = "Maximum Value per year", xaxis = list(title="Year"), yaxis = list(title="Maximum Value"))  %>% add_segments(x = 1940, xend = 2009, y = 140, yend = 140, line = list(color = 'red', width = 2))
# Create linear model
mod1 <- lm(max_sea_level ~ year, data = venice_max)
summary(mod1)
# Predictions of 13 next years using the linear model
mod1_predict <- predict.lm(mod1,newdata=data.frame("year"=c(2010:2022)),se=T, interval = "confidence", level = 0.95)
mod1_predict
# Stored the predictions in a dataframe
venice_max_predict <- data.frame(
PredictedValues = mod1_predict) %>%
mutate(year = c(2010:2022))
head(venice_max_predict)
#Plot the confidence intervals
plotCI(x = venice_max_predict$year,
y = venice_max_predict$PredictedValues.fit.fit,
li = venice_max_predict$PredictedValues.fit.lwr,
ui = venice_max_predict$PredictedValues.fit.upr)
#Create a new dataframe for the extreme values of 2010 - 2022 (table from Wikipedia)
max_real <- data.frame(year = c(2012, 2012, 2013, 2018, 2019, 2019, 2019, 2022), max_sea_level = c(143, 149, 143, 156, 187, 144, 154, 204))
# Create the ggplot object
venice_plot <- ggplot() +
geom_point(data = max_real, aes(x = year, y = max_sea_level, color = "Observed"), alpha = 0.5, show.legend = TRUE, name = "Observed") +
geom_point(data = venice_max_predict, aes(x = year, y = PredictedValues.fit.fit, color = "Predicted"), shape = 1, show.legend = TRUE, name = "Predicted") +
labs(title = "Predicted Yearly Max Values vs Observed Values (>140cm)", x = "Year", y = "Sea Level") +
scale_x_continuous(breaks = unique(c(venice_max_predict$year, max_real$year))) +
scale_color_manual(name = "Data Type", values = c("Observed" = "red", "Predicted" = "black")) +
theme(legend.title = element_blank())
# Convert the ggplot object to a Plotly interactive plot
interactive_venice_plot <- ggplotly(venice_plot)
# Add the confidence interval as a separate trace
interactive_venice_plot <- interactive_venice_plot %>%
add_ribbons(data = venice_max_predict, x = ~year, ymin = ~PredictedValues.fit.lwr, ymax = ~PredictedValues.fit.upr, color = I("blue"), showlegend = TRUE, name = "Confidence Interval")
# Display the interactive plot
interactive_venice_plot
plot(gev_time_varying_linear)
source(here::here("script/setup.R"))
# Read the Data
venice <- venice90
# Using block maxima approach to have the maximum sea level per year
venice_max <- venice %>%
group_by(year) %>%
summarise(max_sea_level = max(sealevel))
head(venice_max)
plot_ly(venice_max, x = ~year, y = ~max_sea_level, type = 'scatter', mode = 'markers', name = 'Max Value') %>% layout(title = "Maximum Value per year", xaxis = list(title="Year"), yaxis = list(title="Maximum Value"))  %>% add_segments(x = 1940, xend = 2009, y = 140, yend = 140, line = list(color = 'red', width = 2))
# Create linear model
mod1 <- lm(max_sea_level ~ year, data = venice_max)
summary(mod1)
# Predictions of 13 next years using the linear model
mod1_predict <- predict.lm(mod1,newdata=data.frame("year"=c(2010:2022)),se=T, interval = "confidence", level = 0.95)
mod1_predict
# Stored the predictions in a dataframe
venice_max_predict <- data.frame(
PredictedValues = mod1_predict) %>%
mutate(year = c(2010:2022))
head(venice_max_predict)
#Plot the confidence intervals
plotCI(x = venice_max_predict$year,
y = venice_max_predict$PredictedValues.fit.fit,
li = venice_max_predict$PredictedValues.fit.lwr,
ui = venice_max_predict$PredictedValues.fit.upr)
#Create a new dataframe for the extreme values of 2010 - 2022 (table from Wikipedia)
max_real <- data.frame(year = c(2012, 2012, 2013, 2018, 2019, 2019, 2019, 2022), max_sea_level = c(143, 149, 143, 156, 187, 144, 154, 204))
# Create the ggplot object
venice_plot <- ggplot() +
geom_point(data = max_real, aes(x = year, y = max_sea_level, color = "Observed"), alpha = 0.5, show.legend = TRUE, name = "Observed") +
geom_point(data = venice_max_predict, aes(x = year, y = PredictedValues.fit.fit, color = "Predicted"), shape = 1, show.legend = TRUE, name = "Predicted") +
labs(title = "Predicted Yearly Max Values vs Observed Values (>140cm)", x = "Year", y = "Sea Level") +
scale_x_continuous(breaks = unique(c(venice_max_predict$year, max_real$year))) +
scale_color_manual(name = "Data Type", values = c("Observed" = "red", "Predicted" = "black")) +
theme(legend.title = element_blank())
# Convert the ggplot object to a Plotly interactive plot
interactive_venice_plot <- ggplotly(venice_plot)
# Add the confidence interval as a separate trace
interactive_venice_plot <- interactive_venice_plot %>%
add_ribbons(data = venice_max_predict, x = ~year, ymin = ~PredictedValues.fit.lwr, ymax = ~PredictedValues.fit.upr, color = I("blue"), showlegend = TRUE, name = "Confidence Interval")
# Display the interactive plot
interactive_venice_plot
plot(gev_time_varying_linear)
source(here::here("script/setup.R"))
# Read the Data
venice <- venice90
# Using block maxima approach to have the maximum sea level per year
venice_max <- venice %>%
group_by(year) %>%
summarise(max_sea_level = max(sealevel))
head(venice_max)
plot_ly(venice_max, x = ~year, y = ~max_sea_level, type = 'scatter', mode = 'markers', name = 'Max Value') %>% layout(title = "Maximum Value per year", xaxis = list(title="Year"), yaxis = list(title="Maximum Value"))  %>% add_segments(x = 1940, xend = 2009, y = 140, yend = 140, line = list(color = 'red', width = 2))
# Create linear model
mod1 <- lm(max_sea_level ~ year, data = venice_max)
summary(mod1)
# Predictions of 13 next years using the linear model
mod1_predict <- predict.lm(mod1,newdata=data.frame("year"=c(2010:2022)),se=T, interval = "confidence", level = 0.95)
mod1_predict
# Stored the predictions in a dataframe
venice_max_predict <- data.frame(
PredictedValues = mod1_predict) %>%
mutate(year = c(2010:2022))
head(venice_max_predict)
#Plot the confidence intervals
plotCI(x = venice_max_predict$year,
y = venice_max_predict$PredictedValues.fit.fit,
li = venice_max_predict$PredictedValues.fit.lwr,
ui = venice_max_predict$PredictedValues.fit.upr)
#Create a new dataframe for the extreme values of 2010 - 2022 (table from Wikipedia)
max_real <- data.frame(year = c(2012, 2012, 2013, 2018, 2019, 2019, 2019, 2022), max_sea_level = c(143, 149, 143, 156, 187, 144, 154, 204))
# Create the ggplot object
venice_plot <- ggplot() +
geom_point(data = max_real, aes(x = year, y = max_sea_level, color = "Observed"), alpha = 0.5, show.legend = TRUE, name = "Observed") +
geom_point(data = venice_max_predict, aes(x = year, y = PredictedValues.fit.fit, color = "Predicted"), shape = 1, show.legend = TRUE, name = "Predicted") +
labs(title = "Predicted Yearly Max Values vs Observed Values (>140cm)", x = "Year", y = "Sea Level") +
scale_x_continuous(breaks = unique(c(venice_max_predict$year, max_real$year))) +
scale_color_manual(name = "Data Type", values = c("Observed" = "red", "Predicted" = "black")) +
theme(legend.title = element_blank())
# Convert the ggplot object to a Plotly interactive plot
interactive_venice_plot <- ggplotly(venice_plot)
# Add the confidence interval as a separate trace
interactive_venice_plot <- interactive_venice_plot %>%
add_ribbons(data = venice_max_predict, x = ~year, ymin = ~PredictedValues.fit.lwr, ymax = ~PredictedValues.fit.upr, color = I("blue"), showlegend = TRUE, name = "Confidence Interval")
# Display the interactive plot
interactive_venice_plot
# Practical 2
```{r, echo = FALSE, message = FALSE, warning=FALSE}
source(here::here("script/setup.R"))
# Read the Data
venice <- venice90
# Using block maxima approach to have the maximum sea level per year
venice_max <- venice %>%
group_by(year) %>%
summarise(max_sea_level = max(sealevel))
head(venice_max)
plot_ly(venice_max, x = ~year, y = ~max_sea_level, type = 'scatter', mode = 'markers', name = 'Max Value') %>% layout(title = "Maximum Value per year", xaxis = list(title="Year"), yaxis = list(title="Maximum Value"))  %>% add_segments(x = 1940, xend = 2009, y = 140, yend = 140, line = list(color = 'red', width = 2))
# Create linear model
mod1 <- lm(max_sea_level ~ year, data = venice_max)
summary(mod1)
# Predictions of 13 next years using the linear model
mod1_predict <- predict.lm(mod1,newdata=data.frame("year"=c(2010:2022)),se=T, interval = "confidence", level = 0.95)
mod1_predict
# Stored the predictions in a dataframe
venice_max_predict <- data.frame(
PredictedValues = mod1_predict) %>%
mutate(year = c(2010:2022))
head(venice_max_predict)
#Plot the confidence intervals
plotCI(x = venice_max_predict$year,
y = venice_max_predict$PredictedValues.fit.fit,
li = venice_max_predict$PredictedValues.fit.lwr,
ui = venice_max_predict$PredictedValues.fit.upr)
#Create a new dataframe for the extreme values of 2010 - 2022 (table from Wikipedia)
max_real <- data.frame(year = c(2012, 2012, 2013, 2018, 2019, 2019, 2019, 2022), max_sea_level = c(143, 149, 143, 156, 187, 144, 154, 204))
# Create the ggplot object
venice_plot <- ggplot() +
geom_point(data = max_real, aes(x = year, y = max_sea_level, color = "Observed"), alpha = 0.5, show.legend = TRUE, name = "Observed") +
geom_point(data = venice_max_predict, aes(x = year, y = PredictedValues.fit.fit, color = "Predicted"), shape = 1, show.legend = TRUE, name = "Predicted") +
labs(title = "Predicted Yearly Max Values vs Observed Values (>140cm)", x = "Year", y = "Sea Level") +
scale_x_continuous(breaks = unique(c(venice_max_predict$year, max_real$year))) +
scale_color_manual(name = "Data Type", values = c("Observed" = "red", "Predicted" = "black")) +
theme(legend.title = element_blank())
# Convert the ggplot object to a Plotly interactive plot
interactive_venice_plot <- ggplotly(venice_plot)
# Add the confidence interval as a separate trace
interactive_venice_plot <- interactive_venice_plot %>%
add_ribbons(data = venice_max_predict, x = ~year, ymin = ~PredictedValues.fit.lwr, ymax = ~PredictedValues.fit.upr, color = I("blue"), showlegend = TRUE, name = "Confidence Interval")
# Display the interactive plot
interactive_venice_plot
plot(gev_time_varying_linear)
source(here::here("script/setup.R"))
# Read the Data
venice <- venice90
# Using block maxima approach to have the maximum sea level per year
venice_max <- venice %>%
group_by(year) %>%
summarise(max_sea_level = max(sealevel))
head(venice_max)
plot_ly(venice_max, x = ~year, y = ~max_sea_level, type = 'scatter', mode = 'markers', name = 'Max Value') %>% layout(title = "Maximum Value per year", xaxis = list(title="Year"), yaxis = list(title="Maximum Value"))  %>% add_segments(x = 1940, xend = 2009, y = 140, yend = 140, line = list(color = 'red', width = 2))
# Create linear model
mod1 <- lm(max_sea_level ~ year, data = venice_max)
summary(mod1)
# Predictions of 13 next years using the linear model
mod1_predict <- predict.lm(mod1,newdata=data.frame("year"=c(2010:2022)),se=T, interval = "confidence", level = 0.95)
mod1_predict
# Stored the predictions in a dataframe
venice_max_predict <- data.frame(
PredictedValues = mod1_predict) %>%
mutate(year = c(2010:2022))
head(venice_max_predict)
#Plot the confidence intervals
plotCI(x = venice_max_predict$year,
y = venice_max_predict$PredictedValues.fit.fit,
li = venice_max_predict$PredictedValues.fit.lwr,
ui = venice_max_predict$PredictedValues.fit.upr)
#Create a new dataframe for the extreme values of 2010 - 2022 (table from Wikipedia)
max_real <- data.frame(year = c(2012, 2012, 2013, 2018, 2019, 2019, 2019, 2022), max_sea_level = c(143, 149, 143, 156, 187, 144, 154, 204))
# Create the ggplot object
venice_plot <- ggplot() +
geom_point(data = max_real, aes(x = year, y = max_sea_level, color = "Observed"), alpha = 0.5, show.legend = TRUE, name = "Observed") +
geom_point(data = venice_max_predict, aes(x = year, y = PredictedValues.fit.fit, color = "Predicted"), shape = 1, show.legend = TRUE, name = "Predicted") +
labs(title = "Predicted Yearly Max Values vs Observed Values (>140cm)", x = "Year", y = "Sea Level") +
scale_x_continuous(breaks = unique(c(venice_max_predict$year, max_real$year))) +
scale_color_manual(name = "Data Type", values = c("Observed" = "red", "Predicted" = "black")) +
theme(legend.title = element_blank())
# Convert the ggplot object to a Plotly interactive plot
interactive_venice_plot <- ggplotly(venice_plot)
# Add the confidence interval as a separate trace
interactive_venice_plot <- interactive_venice_plot %>%
add_ribbons(data = venice_max_predict, x = ~year, ymin = ~PredictedValues.fit.lwr, ymax = ~PredictedValues.fit.upr, color = I("blue"), showlegend = TRUE, name = "Confidence Interval")
# Display the interactive plot
interactive_venice_plot
plot(gev_time_varying_linear) ; plot(gev_time_varying_harmonic) ; gev_time_varying_linear$results$par ; gev_time_varying_harmonic$results$par;  return.level(gev_time_varying_linear) ; return.level(gev_time_varying_harmonic)
# First we unlist our data frame
list_max_sea_levels <- unlist(venice_max$max_sea_level)
# GEV model with fixed location
gev_fix <- fevd(list_max_sea_levels, type = "GEV", time.units= "year")
plot(gev_fix) ; gev_fix$results$par ; return.level(gev_fix) # shape is almost equal to 0.
# Compute confidence interval
ci(gev_fix, type= "parameter") # CI includes 0
# GEV model with varying time-location using both linear and harmonic function
yy <- 1:length(venice_max$year)
gev_time_varying_linear <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units= "year", location.fun = ~ yy)
gev_time_varying_harmonic <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units= "year", location.fun = ~sin(2 * pi * (year - 1940)/70) + cos(2 * pi * (year - 1940)/70))
plot(gev_time_varying_linear)
return.level(gev_time_varying_linear)
gev_time_varying_linear$results$par
