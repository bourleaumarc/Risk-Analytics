cov_data <- distill(gev_time_varying_harmonic, cov = TRUE)
gev.rl <- return.level(x = gev_time_varying_harmonic, return.period = c(13),
do.ci = TRUE, alpha = 0.05, qcov = cov_data)
gev.rl <- return.level(x = gev_time_varying_harmonic, return.period = c(13),
do.ci = TRUE, alpha = 0.05, qcov = distill(gev_time_varying_harmonic, cov = TRUE))
cov_data <- distill(gev_time_varying_harmonic, cov = TRUE)
cov_data
gev.rl <- return.level(x = gev_time_varying_harmonic, return.period = c(13),
do.ci = TRUE, alpha = 0.05, qcov = cov_data)
cov_data
?distill
cov_data <- distill.matrix(gev_time_varying_harmonic, cov = TRUE)
cov_data <- distill.fevd(gev_time_varying_harmonic, cov = TRUE)
gev.rl <- return.level(x = gev_time_varying_harmonic, return.period = c(13),
do.ci = TRUE, alpha = 0.05, qcov = cov_data)
cov_data <- distill.list(gev_time_varying_harmonic, cov = TRUE)
gev.rl <- return.level(x = gev_time_varying_harmonic, return.period = c(13),
do.ci = TRUE, alpha = 0.05, qcov = cov_data)
View(cov_data)
cov_data <- distill.matrix(gev_time_varying_harmonic, cov = TRUE)
attributes(gev_time_varying_harmonic)
cov_data <- distill.matrix(gev_time_varying_harmonic, cov.data = TRUE)
?distill
?return.level
?return.level
return.level(gev_time_varying_harmonic)
gev_time_varying_harmonic
return.level(gev_time_varying_harmonic)
gev_time_varying_harmonic
return.level(gev_time_varying_harmonic)
gev_time_varying_harmonic
as.numeric(gev_time_varying_harmonic$results$par[1]+gev_time_varying_harmonic$results$par[4]*((-log(1-1/13))^(-gev_time_varying_harmonic$results$par[5])-1)/gev_time_varying_harmonic$results$par[5])
knitr::opts_chunk$set(echo = TRUE)
library(ismev)
library(VGAM)
library(tidyverse)
library(plotly)
library(plotrix)
library(scales)
library(extRemes)
# Read the Data
venice <- venice90
# Using block maxima approach to have the maximum sea level per year
venice_max <- venice %>%
group_by(year) %>%
summarise(max_sea_level = max(sealevel))
head(venice_max)
plot_ly(venice_max, x = ~year, y = ~max_sea_level, type = 'scatter', mode = 'markers', name = 'Max Value') %>% layout(title = "Maximum Value per year", xaxis = list(title="Year"), yaxis = list(title="Maximum Value"))  %>% add_segments(x = 1940, xend = 2009, y = 140, yend = 140, line = list(color = 'red', width = 2))
# Create linear model
mod1 <- lm(max_sea_level ~ year, data = venice_max)
summary(mod1)
# Predictions of 13 next years using the linear model
mod1_predict <- predict.lm(mod1,newdata=data.frame("year"=c(2010:2022)),se=T, interval = "confidence", level = 0.95)
mod1_predict
# Stored the predictions in a dataframe
venice_max_predict <- data.frame(
PredictedValues = mod1_predict) %>%
mutate(year = c(2010:2022))
head(venice_max_predict)
#Plot the confidence intervals
plotCI(x = venice_max_predict$year,
y = venice_max_predict$PredictedValues.fit.fit,
li = venice_max_predict$PredictedValues.fit.lwr,
ui = venice_max_predict$PredictedValues.fit.upr)
#Create a new dataframe for the extreme values of 2010 - 2022 (table from Wikipedia)
max_real <- data.frame(year = c(2012, 2012, 2013, 2018, 2019, 2019, 2019, 2022), max_sea_level = c(143, 149, 143, 156, 187, 144, 154, 204))
# Create the ggplot object
venice_plot <- ggplot() +
geom_point(data = max_real, aes(x = year, y = max_sea_level, color = "Observed"), alpha = 0.5, show.legend = TRUE, name = "Observed") +
geom_point(data = venice_max_predict, aes(x = year, y = PredictedValues.fit.fit, color = "Predicted"), shape = 1, show.legend = TRUE, name = "Predicted") +
labs(title = "Predicted Yearly Max Values vs Observed Values (>140cm)", x = "Year", y = "Sea Level") +
scale_x_continuous(breaks = unique(c(venice_max_predict$year, max_real$year))) +
scale_color_manual(name = "Data Type", values = c("Observed" = "red", "Predicted" = "black")) +
theme(legend.title = element_blank())
# Convert the ggplot object to a Plotly interactive plot
interactive_venice_plot <- ggplotly(venice_plot)
# Add the confidence interval as a separate trace
interactive_venice_plot <- interactive_venice_plot %>%
add_ribbons(data = venice_max_predict, x = ~year, ymin = ~PredictedValues.fit.lwr, ymax = ~PredictedValues.fit.upr, color = I("blue"), showlegend = TRUE, name = "Confidence Interval")
# Display the interactive plot
interactive_venice_plot
########################################## extRemes ##########################################
# First we unlist our data frame
list_max_sea_levels <- unlist(venice_max$max_sea_level)
# GEV model with fixed location
gev_fix <- fevd(list_max_sea_levels, type = "GEV", time.units= "year")
plot(gev_fix) ; gev_fix$results$par ; return.level(gev_fix) # shape is almost equal to 0.
# Compute confidence interval
ci(gev_fix, type= "parameter") # CI includes 0
# GEV model with varying time-location using both linear and harmonic function
yy <- 1:length(venice_max$year)
gev_time_varying_linear <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units= "year", location.fun = ~ yy)
gev_time_varying_harmonic <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units= "year", location.fun = ~sin(2 * pi * (year - 1940)/70) + cos(2 * pi * (year - 1940)/70))
plot(gev_time_varying_linear) ; plot(gev_time_varying_harmonic) ; gev_time_varying_linear$results$par ; gev_time_varying_harmonic$results$par;  return.level(gev_time_varying_linear) ; return.level(gev_time_varying_harmonic)
# Compare the two models using likelihood ratio test: Ho: no significant difference in model fit H1: there is a significant difference in model fit between the two models.
lrt_result_linear <- lr.test(gev_fix, gev_time_varying_linear) # we can almost reject the null hypothesis at 95% significant level, which make sense as we have indications that the distribution is non-stationary
lrt_result_harmonic <-lr.test(gev_fix, gev_time_varying_harmonic)
attributes(gev_time_varying_linear)
# 589.5372 linear --> this is sufficient as lower AIC
# 594.9147 harmonic --> too complex, we stick with the linear (time varying location)
# Fit a GEV model with time-varying scale
gev_time_varying_scale <-  fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units = "year", scale.fun = ~ yy) # AIC: 600
gev_time_varying_shape <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units = "year", shape.fun = ~ yy) # AIC:  600.7072
gev_time_varying_scale_shape <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units = "year", shape.fun = ~ yy, scale.fun = ~ yy ) # AIC: 601.9
gev_time_varying_location_scale <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units = "year", scale.fun = ~ yy, location.fun =  ~ yy) # AIC: 590.6
gev_time_varying_location_shape <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units = "year", shape.fun = ~ yy, location.fun =  ~ yy) # AIC: 586
gev_time_varying_scale_shape_location <- fevd(venice_max$max_sea_level, venice_max, type = "GEV", time.units = "year", shape.fun = ~ yy, location.fun =  ~ yy, scale.fun = ~ yy ) # AIC: 586
lrt_result <- lr.test(gev_time_varying_location_shape, gev_time_varying_scale_shape_location) # can't reject the null hypothesis so we decide to choose the gev_time_varying_location_shape
return_levels_df <- data.frame(return_level = numeric())  # Create an empty data frame with a column "return_level"
for (i in 71:83) {
loc <- gev_time_varying_location_shape$results$par[1] + gev_time_varying_location_shape$results$par[2] * i
scale <- gev_time_varying_location_shape$results$par[3]
shape <- gev_time_varying_location_shape$results$par[4] + gev_time_varying_location_shape$results$par[5] * i
return_level <- qgev(1 - 1/13, location = loc, scale = scale, shape = shape)
return_levels_df <- rbind(return_levels_df, data.frame(return_level = return_level))
}
# Assign sequential numeric row names
rownames(return_levels_df) <- 1:nrow(return_levels_df)
print(return_levels_df)
knitr::opts_chunk$set(echo = TRUE)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.example.com"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes("CSS_SELECTOR_FOR_PRODUCT_CONTAINER") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes("CSS_SELECTOR_FOR_PRODUCT_NAME") %>% html_text(),
brand = products %>% html_nodes("CSS_SELECTOR_FOR_BRAND") %>% html_text(),
original_price = products %>% html_nodes("CSS_SELECTOR_FOR_ORIGINAL_PRICE") %>% html_text(),
discounted_price = products %>% html_nodes("CSS_SELECTOR_FOR_DISCOUNTED_PRICE") %>% html_text()
)
# Print the data
print(data)
View(data)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes("CSS_SELECTOR_FOR_PRODUCT_CONTAINER") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes("CSS_SELECTOR_FOR_PRODUCT_NAME") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes("CSS_SELECTOR_FOR_ORIGINAL_PRICE") %>% html_text(),
discounted_price = products %>% html_nodes("CSS_SELECTOR_FOR_DISCOUNTED_PRICE") %>% html_text()
)
# Print the data
print(data)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid js-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes("CSS_SELECTOR_FOR_PRODUCT_NAME") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes("CSS_SELECTOR_FOR_ORIGINAL_PRICE") %>% html_text(),
discounted_price = products %>% html_nodes("CSS_SELECTOR_FOR_DISCOUNTED_PRICE") %>% html_text()
)
# Print the data
print(data)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid.fijs-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes(".b-product-tile-price-item b-product-tile-price-item--line-through") %>% html_text()
)
# Print the data
print(data)
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid.fijs-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text()
library(rvest)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes(".b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
View(data)
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text()
View(data)
View(data)
products <- page %>%
html_nodes(".b-product-grid.js-product-grid") %>%
html_children()
View(products)
products <- page %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_children()
products <- page %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes(".b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
# Print the data
print(data)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes(".b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
# Print the data
print(data)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes(".b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
# Print the data
print(data)
products <- page %>%
html_nodes(".b-product-grid.js-product-grid") %>%
html_children()
html_children
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid.js-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-title") %>% html_text()
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid.js-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text())
View(data)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid.js-product-grid") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes("b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes("b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text())
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text()),
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text()),
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes("b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
library(rvest)
library(dplyr)
# Define the URL
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=undefined"
# Read the HTML content from the website
page <- read_html(url)
# Extract product details
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
# Extract information for each product
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes("b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
print(length(name_nodes))
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text()
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
products <- page %>%
html_nodes(".b-product-grid-tile-outer.js-product-tiles") %>%
html_children()
# Extract product details
products <- page %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_children()
data <- tibble(
name = products %>% html_nodes(".b-product-tile-link.js-product-tile-link") %>% html_text(),
brand = products %>% html_nodes(".b-product-tile-brand.b-product-tile-text.js-product-tile-link") %>% html_text(),
original_price = products %>% html_nodes(".b-product-tile-price-item") %>% html_text(),
discounted_price = products %>% html_nodes("b-product-tile-price-item.b-product-tile-price-item--line-through") %>% html_text()
)
url <- "https://www.snipes.ch/fr/c/shoes?srule=Standard&prefn1=isSale&prefv1=true&openCategory=true&sz=349"
scrap_data_fun <- function(url_link) {
url_html <- url_link %>%
read_html()
# Scraping brand information
brand_text <- url_html %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-brand-colours span") %>%
html_text() %>%
str_remove_all("\n")
# Scraping name information
name_text <- url_html %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-title-container div.b-product-tile-title.b-product-tile-text span") %>%
html_text() %>%
str_remove_all("\n")
# Scraping discounted price information
discounts <- url_html %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-price div span:nth-child(2) span") %>%
html_text() %>%
str_remove_all("\n") %>%
str_remove_all("CHF ") %>%
str_replace_all(",", ".") %>%
as.numeric()
# Scraping original price information
prices <- url_html %>%
html_nodes("div.b-product-grid-tile-outer.js-product-tiles div div div div.b-product-tile-info-container div a div.b-product-tile-price div span.b-product-tile-price-outer.b-product-tile-price-outer--line-through span") %>%
html_text() %>%
str_remove_all("\n") %>%
str_remove_all("CHF ") %>%
str_replace_all(",", ".") %>%
as.numeric()
# Create a data frame with brand and name columns
snipes_df <- data.frame(brand = brand_text, name = name_text, original_price = prices, discounted_prices = discounts)
}
snipes_df <- scrap_data_fun(url)
View(snipes_df)
View(snipes_df)
library(ggplot2)
# Calculate absolute discount
snipes_df <- snipes_df %>%
mutate(absolute_discount = original_price - discounted_price)
# Calculate absolute discount
snipes_df <- snipes_df %>%
mutate(absolute_discount = original_price - discounted_prices)
# Generate scatter plot
ggplot(snipes_df, aes(x = original_price, y = absolute_discount, color = brand)) +
geom_point() +
labs(x = "Original Price", y = "Absolute Discount", title = "Discounts by Original Price and Brand") +
theme_minimal() +
scale_color_discrete(name = "Brand") # Adjust the name of the legend if needed
library(plotly)
# Calculate absolute discount
snipes_df <- snipes_df %>%
mutate(absolute_discount = original_price - discounted_prices)
# Generate ggplot
p <- ggplot(snipes_df, aes(x = original_price, y = absolute_discount, color = brand)) +
geom_point() +
labs(x = "Original Price", y = "Absolute Discount", title = "Discounts by Original Price and Brand") +
theme_minimal() +
scale_color_discrete(name = "Brand") # Adjust the name of the legend if needed
# Convert to an interactive plotly object
ggplotly(p)
# Calculate absolute discount
snipes_df <- snipes_df %>%
mutate(absolute_discount = discounted_prices - original_price)
# Generate ggplot
p <- ggplot(snipes_df, aes(x = original_price, y = absolute_discount, color = brand)) +
geom_point() +
labs(x = "Original Price", y = "Absolute Discount", title = "Discounts by Original Price and Brand") +
theme_minimal() +
scale_color_discrete(name = "Brand") # Adjust the name of the legend if needed
# Convert to an interactive plotly object
ggplotly(p)
write.csv(snipes_df, "snipes_data.csv", row.names = FALSE)
