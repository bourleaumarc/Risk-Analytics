# Practical 1

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, collapse = TRUE)
knitr::knit_hooks$set(inline = function(x){
  x <- sprintf("%1.2f", x)
  paste(x, collapse = ", ")
})
```

```{r, echo = FALSE, message = FALSE, warning=FALSE}
source(here::here("script/setup.R"))
```

## Part 1: financial returns and normality

### (a) Read in the data and assess the stationarity of the raw stock indices.

We are going to use two methods. The first one, is to visualize the stock indices over time to get a sense of whether they appear stationary or not; using `plot()`.

```{r question a }
# Create interactive plots for each index
plot_sp500 <- plot_ly(x = sp500.df$DATE, y = sp500.df$SP500, type = "scatter", mode = "lines", name = "SP500") %>%
  layout(title = "SP500")

plot_cac40 <- plot_ly(x = cac40.df$DATE, y = cac40.df$CAC40, type = "scatter", mode = "lines", name = "CAC40") %>%
  layout(title = "CAC40")

plot_nasdaq <- plot_ly(x = nasdaq.df$DATE, y = nasdaq.df$NASDAQ, type = "scatter", mode = "lines", name = "Nasdaq") %>%
  layout(title = "Nasdaq")

plot_nikkei <- plot_ly(x = nikkei.df$DATE, y = nikkei.df$NIKKEI, type = "scatter", mode = "lines", name = "NIKKEI") %>%
  layout(title = "NIKKEI")

combined_plot <- subplot(plot_sp500, plot_cac40, plot_nasdaq, plot_nikkei, nrows = 2)

# Set a common title for the entire grid
combined_plot <- layout(combined_plot, title = "Comparison of Stock Indices")

# Show the combined plot
combined_plot

```

It appears that none of the stock indices are stationary based on the plots generated. These plots clearly show the presence of trends, which are a strong indicator of non-stationarity data. For instance, if we take the NASDAQ index as an example, it exhibits a noticeable upward trend between 1999 and the beginning of 2000.

Another common approach is to use the Augmented-Dickey-Fuller (ADF) test. If we can reject the null hypothesis (p-value \< 0.05), then we can consider the time-series to be stationary. The null hypothesis of this test is that the time series is non-stationary. If the p-value is less than your significance level, you can reject the null hypothesis and consider the series stationary.

```{r question a: adf test}
# ADF - Test 
adf_test_sp500 <- adf.test(sp500$SP500) ; adf_test_sp500
adf_test_nasdaq <- adf.test(nasdaq$NASDAQ) ; adf_test_nasdaq
adf_test_cac40 <- adf.test(cac40$CAC40) ; adf_test_cac40
adf_test_nikkei <- adf.test(nikkei$NIKKEI) ; adf_test_nikkei
```

We can't reject any of the null hypothesis, implying that we do not have enough evidence to conclude that the data is stationary.

### (b) Create a function to transform the daily stock indices into their daily negative log returns counterparts. Plot the latter series and assess their stationarity. To compare the series, also plot the negative log returns on a common scale to all indices.

```{r question b}
# Define a function to calculate negative log returns
calculate_log_returns <- function(stocks) {
  log_returns <- -diff(log(stocks))
  return(log_returns)
}
# Calculate negative log returns for each index
log_returns_sp500 <- calculate_log_returns(sp500) %>% na.omit()
log_returns_cac40 <- calculate_log_returns(cac40) %>% na.omit()
log_returns_nasdaq <- calculate_log_returns(nasdaq) %>% na.omit()
log_returns_nikkei <- calculate_log_returns(nikkei) %>% na.omit()
# We need to transform the index of rows as a separate variable to include the date into the plots: we create a function
log_returns_sp500$Dates <- rownames(log_returns_sp500)
log_returns_sp500.df <- data.frame(log_returns_sp500)
log_returns_cac40$Dates <- rownames(log_returns_cac40)
log_returns_cac40.df <- data.frame(log_returns_cac40)
log_returns_nasdaq$Dates <- rownames(log_returns_nasdaq)
log_returns_nasdaq.df <- data.frame(log_returns_nasdaq)
log_returns_nikkei$Dates <- rownames(log_returns_nikkei)
log_returns_nikkei.df <- data.frame(log_returns_nikkei)
# Plot for SP500
plot_sp5002 <- plot_ly(x = log_returns_sp500.df$Dates, y = log_returns_sp500, type = "scatter", mode = "lines", name = "SP500") %>% layout(title = "SP500 Negative Log Returns", xaxis = list(title = "Time"), yaxis = list(title = "Negative Log Returns"), shapes = list(list(type = "line", x0 = 1, x1 = length(log_returns_sp500), y0 = 0, y1 = 0, line = list(color = "red"))))

# Plot for CAC40
plot_cac402 <- plot_ly(x = log_returns_cac40.df$Dates, y = log_returns_cac40, type = "scatter", mode = "lines", name = "CAC40") %>% layout(title = "CAC40 Negative Log Returns", xaxis = list(title = "Time"), yaxis = list(title = "Negative Log Returns"), shapes = list(list(type = "line", x0 = 1, x1 = length(log_returns_cac40), y0 = 0, y1 = 0, line = list(color = "red"))))

# Plot for Nasdaq
plot_nasdaq2 <- plot_ly(x = log_returns_nasdaq.df$Dates , y = log_returns_nasdaq, type = "scatter", mode = "lines", name = "Nasdaq") %>% layout(title = "Nasdaq Negative Log Returns", xaxis = list(title = "Time"), yaxis = list(title = "Negative Log Returns"), shapes = list(list(type = "line", x0 = 1, x1 = length(log_returns_nasdaq), y0 = 0, y1 = 0, line = list(color = "red"))))

# Plot for NIKKEI
plot_nikkei2 <- plot_ly(x = log_returns_nikkei.df$Dates , y = log_returns_nikkei, type = "scatter", mode = "lines", name = "NIKKEI") %>% layout(title = "Negative Log Returns", xaxis = list(title = "Time"), yaxis = list(title = "Negative Log Returns"), shapes = list(list(type = "line", x0 = 1, x1 = length(log_returns_nikkei), y0 = 0, y1 = 0, line = list(color = "red"))))

# Create a subplot with the list of individual plots
combined_plot2 <- subplot(plot_sp5002, plot_cac402, plot_nasdaq2, plot_nikkei2, nrows = 2)
combined_plot2 <- layout(combined_plot2, title = "Comparison of negative log return of Stock Indices (same scale)")
# Show the combined plot
combined_plot2

```

Looking at the comparison of negative logarithm return of the stock indices, we discern the following:

-   mean is not constant: not totally centered around 0, implying that there is a long-term trend in the indexes.

-   variance is not constant: there are clear upward/downward trends. SP500 has very high spikes, such as the one in 1997-10-27.

Therefore, graphically, the indexes seem to be non-stationary.

### (c) Draw histograms of the negative log returns and compare them to the Normal distribution. What do you observe?

```{r question c }
# Set the number of histogram bins
num_bins <- 30
# Create a common scale for the histograms
par(mfrow = c(2, 2))  # Create a 2x2 grid of plots

# Plot histograms and overlay Normal distribution curves
hist(log_returns_sp500, breaks = num_bins, main = "Histogram - SP500 Log Returns", xlab = "Log Returns", probability = TRUE, xlim=c(0.1,-0.1))
curve(dnorm(x, mean = mean(log_returns_sp500), sd = sd(log_returns_sp500)), col = "red", lwd = 2, add = TRUE)

hist(log_returns_cac40, breaks = num_bins, main = "Histogram - CAC40 Log Returns", xlab = "Log Returns", probability = TRUE, xlim=c(0.1,-0.1))
curve(dnorm(x, mean = mean(log_returns_cac40), sd = sd(log_returns_cac40)), col = "red", lwd = 2, add = TRUE)

hist(log_returns_nasdaq, breaks = num_bins, main = "Histogram - Nasdaq Log Returns", xlab = "Log Returns", probability = TRUE, xlim=c(0.1,-0.1))
curve(dnorm(x, mean = mean(log_returns_nasdaq), sd = sd(log_returns_nasdaq)), col = "red", lwd = 2, add = TRUE)

hist(log_returns_nikkei, breaks = num_bins, main = "Histogram - NIKKEI Log Returns", xlab = "Log Returns", probability = TRUE, xlim=c(0.1,-0.1))
curve(dnorm(x, mean = mean(log_returns_nikkei), sd = sd(log_returns_nikkei)), col = "red", lwd = 2, add = TRUE)

# Reset the plot layout
par(mfrow = c(1, 1))



```

In a perfectly normal distribution, the data would closely follow the red curve. The histograms of the stock indices' negative log returns, when compared to the overlaid normal distribution, indicate deviations from normality, suggesting the presence of skewness. Such deviations hold significant implications for the Black-Scholes formula, which assumes normally distributed returns and constant volatility. If returns exhibit heavy tails, as suggested by the histograms, the Black-Scholes model may not accurately capture the risk of extreme price movements, thereby potentially mispricing options that rely on these assumptions.

To validate these observations, further analytical methods will be employed later in this document to rigorously assess the distributional characteristics of the stock indices' returns.

### (d) Check the normality assumption of the negative log returns using QQ-plots. What is your conclusion?

```{r question d }
# Create QQ-plots for log returns

par(mfrow = c(2, 2))  # Create a 2x2 grid of plots

qqnorm(log_returns_sp500, main = "QQ-Plot - SP500 Log Returns")
qqline(log_returns_sp500)
qqnorm(log_returns_cac40, main = "QQ-Plot - CAC40 Log Returns")
qqline(log_returns_cac40)
qqnorm(log_returns_nasdaq, main = "QQ-Plot - Nasdaq Log Returns")
qqline(log_returns_nasdaq)
qqnorm(log_returns_nikkei, main = "QQ-Plot - NIKKEI Log Returns")
qqline(log_returns_nikkei)
```

The QQ-plots for the negative log returns across various stock indices exhibit noticeable deviations from the expected diagonal line, particularly within the tails, which indicates a departure from normal distribution, with a tendency towards more pronounced extreme movements. The Nasdaq index, for instance, distinctly shows this trend with an increased frequency of significant negative returns. The differing scales of the plots also reveal a variable degree of volatility among the indices, with the Nasdaq displaying particularly stark fluctuations. This evidence challenges the assumption of normally distributed returns integral to the Black-Scholes model, suggesting potential inaccuracies in option pricing that relies on this assumption.

In conclusion, the observed anomalies in the QQ-plots signal that the normality assumption critical to the Black-Scholes framework is violated.

### (e) Formally test the normality assumption of the negative log returns using an Anderson-Darling testing procedure. Do you reject the Normal hypothesis?

```{r question e}
# Perform Anderson-Darling test for normality
ad_test_sp500 <- ad.test(log_returns_sp500)
ad_test_cac40 <- ad.test(log_returns_cac40)
ad_test_nasdaq <- ad.test(log_returns_nasdaq)
ad_test_nikkei <- ad.test(log_returns_nikkei)

# Print the results
print(ad_test_sp500)
print(ad_test_cac40)
print(ad_test_nasdaq)
print(ad_test_nikkei)

```

Upon conducting the Anderson-Darling test for normality on the negative log returns of the stock indices, we encounter p-values that effectively round down to zero ((p-value \< 2.2e-16) , providing robust evidence to reject the null hypothesis of normality.

In summary, log returns of the indices are not normally distributed, violating one of the key assumptions behind the Black-Scholes formula.

### (f) Use the `fitdistr()` function from the `MASS` package in order to obtain the (maximum-likelihood estimated) parameters of distributions you could imagine for the negative log returns. Try to fit at least two different distributions on the data and, using an information criteria (such as the AIC), decide which distributional framework fits best for each of the series.

```{r question f, warning=FALSE}
# Fit distributions : normal
fit_sp500 <- fitdistr(log_returns_sp500, "normal")
fit_cac40 <- fitdistr(log_returns_cac40, "normal")
fit_nasdaq <- fitdistr(log_returns_nasdaq, "normal")
fit_nikkei <- fitdistr(log_returns_nikkei, "normal")

# Fit a t-distribution to log returns
fit_sp500_t <- fitdistr(log_returns_sp500, "t")
fit_cac40_t <- fitdistr(log_returns_cac40, "t")
fit_nasdaq_t <- fitdistr(log_returns_nasdaq, "t")
fit_nikkei_t <- fitdistr(log_returns_nikkei, "t")

# Calculate AIC for each distribution
aic_sp500 <- AIC(fit_sp500)
aic_cac40 <- AIC(fit_cac40)
aic_nasdaq <- AIC(fit_nasdaq)
aic_nikkei <- AIC(fit_nikkei)

# Calculate AIC for each distribution
aic_sp500_t <- AIC(fit_sp500_t)
aic_cac40_t <- AIC(fit_cac40_t)
aic_nasdaq_t <- AIC(fit_nasdaq_t)
aic_nikkei_t <- AIC(fit_nikkei_t)

# Create a data frame to store AIC values
aic_data <- data.frame(
  Index = c("SP500", "CAC40", "NASDAQ", "NIKKEI"),
  Normal = c(aic_sp500, aic_cac40, aic_nasdaq, aic_nikkei),
  T_Distribution = c(aic_sp500_t, aic_cac40_t, aic_nasdaq_t, aic_nikkei_t)
)

# Print the AIC data frame
print(aic_data)

# Create a bar plot of AIC values with improved aesthetics
barplot(
  t(as.matrix(aic_data[, -1])),
  beside = TRUE,
  col = c("#1f77b4", "#2ca02c"), # Changed to more appealing colors
  names.arg = aic_data$Index,
  main = "AIC Comparison of Distributions",
  xlab = "Index",
  ylab = "AIC Value",
  cex.names = 0.8,    
  cex.axis = 0.8,    
  cex.main = 1,      
  cex.lab = 0.9,      
  las = 1,            
  border = NA,        
  legend.text = c("Normal", "T-Distribution"),
  args.legend = list(x = "bottomright", bty = "n", cex = 0.8)
)

# You can also add a grid for better readability
grid(nx = NA, ny = NULL, col = "gray", lty = "dotted", lwd = par("lwd"))
```

Upon fitting both normal and t-distributions to the data and evaluating them with the Akaike Information Criterion (AIC), it is important to note that both methods yield similar AIC values. However, the t-distribution consistently offers a better fit for all four indices, as indicated by its slightly lower AIC values. This suggests that while the normal distribution provides a close representation of the data, the student's t-distribution is more likely to minimize information loss when representing the underlying structure of the data, capturing the tails of the distributions more effectively.

As a result, we will continue analyzing the indices with the Student distribution.

### (g) If this has not been done in (f), fit a t-distribution to the negative log returns using `fitdistr()`.Using a QQ-plot for each of the series, decide whether the fit is better than with a Normal distribution, based on your answer in (d).

```{r question g}

# Set up the plotting area for a 4x2 grid
par(mfrow = c(4, 2), mar = c(4, 4, 2, 1), oma = c(0, 0, 3, 0))

# Normal distribution QQ plots
qqnorm(log_returns_sp500, main = "Normal QQ-Plot - SP500")
qqline(log_returns_sp500)
qqnorm(log_returns_cac40, main = "Normal QQ-Plot - CAC40")
qqline(log_returns_cac40)
qqnorm(log_returns_nasdaq, main = "Normal QQ-Plot - NASDAQ")
qqline(log_returns_nasdaq)
qqnorm(log_returns_nikkei, main = "Normal QQ-Plot - NIKKEI")
qqline(log_returns_nikkei)

# t-distribution QQ plots
qqplot(qt(ppoints(log_returns_sp500), df=fit_sp500_t$estimate["df"]), log_returns_sp500, 
       main = "t-dist QQ-Plot - SP500", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")
qqplot(qt(ppoints(log_returns_cac40), df=fit_cac40_t$estimate["df"]), log_returns_cac40, 
       main = "t-dist QQ-Plot - CAC40", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")
qqplot(qt(ppoints(log_returns_nasdaq), df=fit_nasdaq_t$estimate["df"]), log_returns_nasdaq, 
       main = "t-dist QQ-Plot - NASDAQ", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")
qqplot(qt(ppoints(log_returns_nikkei), df=fit_nikkei_t$estimate["df"]), log_returns_nikkei, 
       main = "t-dist QQ-Plot - NIKKEI", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
abline(0, 1, col = "red")

# Reset the plotting area
par(mfrow = c(1, 1))


```

Upon examining the QQ plots, the data points in the t-distribution QQ plots adhere more closely to the reference line, particularly in the tails, suggesting that the t-distribution provides a superior fit for the negative log returns of the indices compared to the normal distribution. This improved alignment, especially in the tails, indicates that the t-distribution more accurately captures the behavior of extreme market movements.

## Part 2: Financial time series, volatility and the random walk hypothesis

### (a) Plot the ACF of all the series in Part 1 (i.e. the raw series as well as the negative log returns). What do you observe?

```{r question 2a}
##############################################################  RAW SERIES ############################################################### 
par(mfrow = c(2, 2))  # Create a 2x2 grid of plots
par(oma = c(0, 0, 3, 0)) # Adjust the outer margins to make space for the title

# Plot ACF for the S&P 500 index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(sp500, main = "ACF of S&P 500 Index")

# Plot ACF for the CAC 40 index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(cac40, main = "ACF of CAC 40 Index")

# Plot ACF for the NASDAQ index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(nasdaq, main = "ACF of NASDAQ Index")

# Plot ACF for the Nikkei index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(nikkei, main = "ACF of Nikkei Index")

# Add the main title
mtext("ACF of raw series", outer = TRUE, cex = 1.5, line = 1)

##############################################################  NEGATIVE LOG RETURNS ################################################################ 

# Setting up the 2x2 plot area with adjusted outer margins for the title
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))

# Plot ACF for the S&P 500 index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_sp500, main = "ACF of S&P 500 Index")

# Plot ACF for the CAC 40 index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_cac40, main = "ACF of CAC 40 Index")

# Plot ACF for the NASDAQ index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_nasdaq, main = "ACF of NASDAQ Index")

# Plot ACF for the Nikkei index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_nikkei, main = "ACF of Nikkei Index")

# Add the central title
mtext("ACF of Negative Log Returns", outer = TRUE, cex = 1.5, line = 0)
```

The Autocorrelation Function (ACF) plots for both the raw series and the negative log returns reveal distinct patterns. For the raw series, the ACF shows a strong, consistent autocorrelation at all lags, indicating a non-stationary process where past values have a persistent influence on future values.

On the other hand, the ACF plots for the negative log returns show most autocorrelations within the confidence bands, implying no significant autocorrelation at any lag. This suggests that the log returns are closer to a stationary process, despite some lags being outside of the confidence bands, indicating that there may be occasional and minor deviations from strict stationarity.

### (b) Use a Ljung-Box procedure to formally test for (temporal) serial dependence in the series. What is your conclusion?

```{r question 2b}
# For Raw Data
box_test_sp500 <- Box.test(sp500, type = "Ljung-Box")
box_test_cac40 <- Box.test(cac40, type = "Ljung-Box")
box_test_nasdaq <- Box.test(nasdaq, type = "Ljung-Box")
box_test_nikkei <- Box.test(nikkei, type = "Ljung-Box")

# For Negative Log Returns
box_test_log_sp500 <- Box.test(log_returns_sp500, type = "Ljung-Box")
box_test_log_cac40 <- Box.test(log_returns_cac40, type = "Ljung-Box")
box_test_log_nasdaq <- Box.test(log_returns_nasdaq, type = "Ljung-Box")
box_test_log_nikkei <- Box.test(log_returns_nikkei, type = "Ljung-Box")

# Print p-values
cat("Raw SP500 Ljung-Box Test - p-value:", box_test_sp500$p.value, "\n")
cat("Raw CAC40 Ljung-Box Test - p-value:", box_test_cac40$p.value, "\n")
cat("Raw NASDAQ Ljung-Box Test - p-value:", box_test_nasdaq$p.value, "\n")
cat("Raw NIKKEI Ljung-Box Test - p-value:", box_test_nikkei$p.value, "\n")

cat("Log Returns SP500 Ljung-Box Test - p-value:", box_test_log_sp500$p.value, "\n")
cat("Log Returns CAC40 Ljung-Box Test - p-value:", box_test_log_cac40$p.value, "\n")
cat("Log Returns NASDAQ Ljung-Box Test - p-value:", box_test_log_nasdaq$p.value, "\n")
cat("Log Returns NIKKEI Ljung-Box Test - p-value:", box_test_log_nikkei$p.value, "\n")

```

For the raw stock market indices, the results indicate strong evidence of serial dependence, with p-values significantly below 0.05 (\<2.2e-16). This suggests that there is a temporal correlation in the raw stock market data, indicating that past observations influence future values.

However, when applying the Ljung-Box test to the negative log returns of these indices, the results show no significant serial dependence. Specifically, for log returns, the p-values are notably higher, with values ranging from 0.0514 to 0.933. This implies that after taking the logarithm of returns, the temporal correlation is greatly reduced, indicating a closer approximation to a stationary process. It's worth noting that the Nikkei index stands out with a p-value of 0.05, signifying a higher degree of autocorrelation in its log returns compared to the other indices.

### (c) Propose ARIMA models for each of the negative log returns series, based on visualisation tools (e.g. ACF and PACF). Select an ARIMA model using `auto.arima()` to each of the negative log returns series. Comment on the difference. Assess the residuals of the resulting models.

```{r question 2c - order, warning= FALSE}
########## PACF gives AR --> p is the order of AR component #################### 
par(mfrow = c(2, 2))  # Create a 2x2 grid of plots
par(oma = c(0, 0, 1, 0))


par(mar = c(5, 4, 3, 2))
pacf(log_returns_sp500)

par(mar = c(5, 4, 3, 2))
pacf(log_returns_cac40)

par(mar = c(5, 4, 3, 2))
pacf(log_returns_nasdaq)

par(mar = c(5, 4, 3, 2))
pacf(log_returns_nikkei)
# Add the central title
mtext("PACF of Negative Log Returns", outer = TRUE, cex = 1.5, line = -0.3)
########## ACF gives MA --> q is the order of MAcomponent #################### 
# Setting up the 2x2 plot area with adjusted outer margins for the title
par(mfrow = c(2, 2), oma = c(0, 0, 2, 0))

# Plot ACF for the S&P 500 index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_sp500, main = "ACF of S&P 500 Index")

# Plot ACF for the CAC 40 index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_cac40, main = "ACF of CAC 40 Index")

# Plot ACF for the NASDAQ index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_nasdaq, main = "ACF of NASDAQ Index")

# Plot ACF for the Nikkei index with adjusted margins
par(mar = c(5, 4, 3, 2))
acf(log_returns_nikkei, main = "ACF of Nikkei Index")

# Add the central title
mtext("ACF of Negative Log Returns", outer = TRUE, cex = 1.5, line = 0)

```

```{r adf test, include= TRUE, warning = FALSE}
################## ADF TEST to see if need to differentiate or not ################## 
# ADF test for SP500 log returns
adf_sp500 <- adf.test(log_returns_sp500)
print(paste("P-value for SP500:", adf_sp500$p.value))

# ADF test for CAC40 log returns
adf_cac40 <- adf.test(log_returns_cac40)
print(paste("P-value for CAC40:", adf_cac40$p.value))

# ADF test for NASDAQ log returns
adf_nasdaq <- adf.test(log_returns_nasdaq)
print(paste("P-value for NASDAQ:", adf_nasdaq$p.value))

# ADF test for NIKKEI log returns
adf_nikkei <- adf.test(log_returns_nikkei)
print(paste("P-value for NIKKEI:", adf_nikkei$p.value))

```

As the p-value is smaller than 0 in the ADF test, we don't need to differentiate because the null hypothesis of the time series is rejected, suggesting that the time series is already stationary.

```{r question 2c - own arima vs auto arima, warning=FALSE}
############################## CHOOSING OUR OWN ORDER ############################## 
# STEP 1: own arima
##ARIMA SP500: order is p, d and q  
arima_sp500 <- Arima(log_returns_sp500, order = c(8,0,7)) # AIC of -22527
arima_sp500
## ARIMA CAC40
arima_cac40 <- Arima(log_returns_cac40, order = c(5,0,5)) # AIC of -14458
arima_cac40
## ARIMA NASDAQ
arima_nasdaq <- Arima(log_returns_nasdaq, order = c(7,0,7))# AIC of -13412
arima_nasdaq
## ARIMA NIKKEI
arima_nikkei <- Arima(log_returns_nikkei, order = c(1,0,1)) # AIC of -14075
arima_nikkei
# STEP 2: residuals 
residuals_sp500 <- residuals(arima_sp500)
residuals_cac40 <- residuals(arima_cac40)
residuals_nasdaq <- residuals(arima_nasdaq)
residuals_nikkei <- residuals(arima_nikkei)
##############################  AUTO ARIMA ############################## 
# STEP 1: auto arima
plot_sp500_auto<- auto.arima(log_returns_sp500) # AIC of -22513
plot_cac40_auto <- auto.arima(log_returns_cac40) # AIC of -14449 
plot_nasdaq_auto <- auto.arima(log_returns_nasdaq)# AIC of -13395 
plot_nikkei_auto <- auto.arima(log_returns_nikkei)# AIC of -14080
# Create comparison plot
par(mfrow = c(2, 2))
plot(residuals_sp500, main = "Residuals - SP500 OWN ARIMA Model")
plot(plot_sp500_auto$residuals, main = "Residuals - SP500 Auto ARIMA Model")
plot(residuals_cac40, main = "Residuals - CAC40 OWN ARIMA Model")
plot(plot_cac40_auto$residuals, main = "Residuals - CAC40 Auto ARIMA Model")
plot(residuals_nasdaq, main = "Residuals - NASDAQ OWN ARIMA Model")
plot(plot_nasdaq_auto$residuals, main = "Residuals - NASDAQ Auto ARIMA Model")
plot(residuals_nikkei, main = "Residuals - NIKKEI OWN ARIMA Model")
plot(plot_nikkei_auto$residuals, main = "Residuals - NIKKEI Auto ARIMA Model")
par(mfrow = c(1, 1))

```

Using `auto.arima` yields better results in terms of AIC. By assessing the residuals, we observe that they might be independent, as their mean is close to 0. When it comes to examining the residuals, there doesn't appear to be a significant visual distinction between the two ARIMA models. To make a thorough assessment, we will analyze their residuals using both the Autocorrelation Function (ACF) and the Ljung-Box test.

### (d) Assess the residuals of the resulting models from (c), both their raw values and their absolute values, through visual tools (such as the ACF) and formal tests (e.g. Ljung-Box). What do you conclude about the independence assumption?

```{r question 2d}
# Ljung-Box test for autocorrelation in residuals
# Obtain raw residuals of OWN ARIMA 
raw_residuals_sp500_own<- residuals(arima_sp500)
raw_residuals_cac40_own<- residuals(arima_cac40)
raw_residuals_nasdaq_own<- residuals(arima_nasdaq)
raw_residuals_nikkei_own<- residuals(arima_nikkei)
# Obtain raw residuals of AUTO ARIMA 
raw_residuals_sp500_auto <- residuals(plot_sp500_auto)
raw_residuals_cac40_auto <- residuals(plot_cac40_auto)
raw_residuals_nasdaq_auto <- residuals(plot_nasdaq_auto)
raw_residuals_nikkei_auto <- residuals(plot_nikkei_auto)

# Obtain absolute residuals of OWN ARIMA 
absolute_residuals_sp500_own <- abs(raw_residuals_sp500_own)
absolute_residuals_cac40_own <- abs(raw_residuals_cac40_own)
absolute_residuals_nasdaq_own <- abs(raw_residuals_nasdaq_own)
absolute_residuals_nikkei_own <- abs(raw_residuals_nikkei_own)
# Obtain absolute residuals of AUTO ARIMA 
absolute_residuals_sp500_auto <- abs(raw_residuals_sp500_auto)
absolute_residuals_cac40_auto <- abs(raw_residuals_cac40_auto)
absolute_residuals_nasdaq_auto <- abs(raw_residuals_nasdaq_auto)
absolute_residuals_nikkei_auto <- abs(raw_residuals_nikkei_auto)
# Plot ACF of raw residuals of OWN ARIMA 
par(mfrow = c(2, 2))
Acf(raw_residuals_sp500_own, main = "SP 500")
Acf(raw_residuals_cac40_own, main = "CAC 40")
Acf(raw_residuals_nasdaq_own, main = "NASDAQ")
Acf(raw_residuals_nikkei_own, main = "NIKKEI")
mtext("ACF of Raw Residuals from OWN ARIMA", outer = TRUE, cex = 1, line = -1)
# Plot ACF of raw residuals of AUTO ARIMA 
par(mfrow = c(2, 2))
Acf(raw_residuals_sp500_auto, main = "SP 500")
Acf(raw_residuals_cac40_auto, main = "CAC 40")
Acf(raw_residuals_nasdaq_auto, main = "NASDAQ")
Acf(raw_residuals_nikkei_auto, main = "NIKKEI")
mtext("ACF of Raw Residuals from AUTO ARIMA", outer = TRUE, cex = 1, line = -1)
# Plot ACF of absolute residuals of OWN ARIMA
par(mfrow = c(2, 2))
Acf(absolute_residuals_sp500_own, main = "SP 500")
Acf(absolute_residuals_cac40_own, main = "CAC40")
Acf(absolute_residuals_nasdaq_own, main = "NASDAQ")
Acf(absolute_residuals_nikkei_own, main = "NIKKEI")
mtext("ACF of Abs Residuals Log Returns from OWN ARIMA", outer = TRUE, cex = 1, line = -1)
# Plot ACF of absolute residuals of AUTO ARIMA 
par(mfrow = c(2, 2))
Acf(absolute_residuals_sp500_auto, main = "SP 500")
Acf(absolute_residuals_cac40_auto, main = "CAC40")
Acf(absolute_residuals_nasdaq_auto, main = "NASDAQ")
Acf(absolute_residuals_nikkei_auto, main = "NIKKEI")
mtext("ACF of Abs Residuals Log Returns from AUTO ARIMA", outer = TRUE, cex = 1, line = -1)
par(mfrow = c(1, 1))
# Ljung-Box test on raw residuals of OWN ARIMA
p_values_raw_own <- sapply(list(
  Box.test(raw_residuals_sp500_own, type = "Ljung-Box"),
  Box.test(raw_residuals_cac40_own, type = "Ljung-Box"),
  Box.test(raw_residuals_nasdaq_own, type = "Ljung-Box"),
  Box.test(raw_residuals_nikkei_own, type = "Ljung-Box")
), function(x) x$p.value)

# Ljung-Box test on raw residuals of AUTO ARIMA
p_values_raw_auto <- sapply(list(
  Box.test(raw_residuals_sp500_auto, type = "Ljung-Box"),
  Box.test(raw_residuals_cac40_auto, type = "Ljung-Box"),
  Box.test(raw_residuals_nasdaq_auto, type = "Ljung-Box"),
  Box.test(raw_residuals_nikkei_auto, type = "Ljung-Box")
), function(x) x$p.value)

# Ljung-Box test on absolute residuals of OWN ARIMA
p_values_abs_own <- sapply(list(
  Box.test(absolute_residuals_sp500_own, type = "Ljung-Box"),
  Box.test(absolute_residuals_cac40_own, type = "Ljung-Box"),
  Box.test(absolute_residuals_nasdaq_own, type = "Ljung-Box"),
  Box.test(absolute_residuals_nikkei_own, type = "Ljung-Box")
), function(x) x$p.value)

# Ljung-Box test on absolute residuals of AUTO ARIMA
p_values_abs_auto <- sapply(list(
  Box.test(absolute_residuals_sp500_auto, type = "Ljung-Box"),
  Box.test(absolute_residuals_cac40_auto, type = "Ljung-Box"),
  Box.test(absolute_residuals_nasdaq_auto, type = "Ljung-Box"),
  Box.test(absolute_residuals_nikkei_auto, type = "Ljung-Box")
), function(x) x$p.value)

# Set scipen option to display p-values in full numeric format
options(scipen = 999)

# Create a data frame with p-values and index names
p_values_data <- data.frame(
  Index = rep(c("SP500", "CAC40", "NASDAQ", "NIKKEI"), each = 4),
  Model = rep(c("Raw (OWN ARIMA)", "Raw (AUTO ARIMA)", "Absolute (OWN ARIMA)", "Absolute (AUTO ARIMA)"), times = 4),
  P_Value = c(p_values_raw_own, p_values_raw_auto, p_values_abs_own, p_values_abs_auto)
)
# Create a kable with the desired styling
kable_output <- kable(p_values_data, format = "html", escape = FALSE, caption = "P-Values from Ljung-Box Test") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE)

# Print the kable to the R console (note: this will not render as HTML in the console)
kable_output


```

The ACF plots and Ljung-Box test results for the ARIMA model residuals---both raw and absolute---highlight concerns regarding the independence of these residuals across the S&P 500, CAC 40, NASDAQ, and Nikkei indices. Notably, the ACF plots for raw residuals indicate significant autocorrelation at various lags for certain indices, suggesting potential residual dependencies. The plots for absolute residuals further underscore this, showing pronounced autocorrelation, especially for the NASDAQ index, indicating the presence of volatility clustering.

Comparative analysis between the AUTO ARIMA and OWN ARIMA models reveals more pronounced autocorrelation in the AUTO ARIMA residuals, suggesting that the OWN ARIMA may better capture the series dynamics to some extent. However, near-zero p-values from the Ljung-Box tests for absolute residuals across all indices decisively reject the null hypothesis of independence, confirming that significant autocorrelation persists.

These findings suggest that while the raw residuals might not always display autocorrelation, their absolute values do, indicating non-constant variance and casting doubt on the adequacy of the models. The implication is clear: a model that can handle conditional variance, such as GARCH, is warranted for a more accurate representation of the financial time series, given the heteroscedastic nature revealed by these tests.

### (e) Plot the volatility of the raw series of indices. What is your conclusion on the homoscedasticity assumption?

```{r question 3e}
# SP500
volatility_sp500 <- volatility(as.vector(sp500.df$SP500))
volatility_cac40 <- volatility(as.vector(cac40.df$CAC40))
volatility_nasdaq <- volatility(as.vector(nasdaq.df$NASDAQ))
volatility_nikkei <- volatility(as.vector(nikkei.df$NIKKEI))
# Create new data frames for each index that combine dates and volatility
sp500_data <- data.frame(Date = sp500.df$DATE, Volatility = volatility_sp500)
cac40_data <- data.frame(Date = cac40.df$DATE, Volatility = volatility_cac40)
nasdaq_data <- data.frame(Date = nasdaq.df$DATE, Volatility = volatility_nasdaq)
nikkei_data <- data.frame(Date = nikkei.df$DATE, Volatility = volatility_nikkei)

# Now plot using the new data frames for the x-axis and y-axis
p <- plot_ly() %>%
    add_trace(data = sp500_data, x = ~Date, y = ~Volatility, name = 'S&P 500', type = 'scatter', mode = 'lines', line = list(color = '#1f77b4')) %>%
    add_trace(data = cac40_data, x = ~Date, y = ~Volatility, name = 'CAC 40', type = 'scatter', mode = 'lines', line = list(color = '#ff7f0e'), visible = F) %>%
    add_trace(data = nasdaq_data, x = ~Date, y = ~Volatility, name = 'NASDAQ', type = 'scatter', mode = 'lines', line = list(color = '#2ca02c'), visible = F) %>%
    add_trace(data = nikkei_data, x = ~Date, y = ~Volatility, name = 'Nikkei', type = 'scatter', mode = 'lines', line = list(color = '#d62728'), visible = F) %>%
    layout(
        title = "Volatility of Major Stock Indices",
        xaxis = list(title = "Date", type = 'date'), # Ensure that the x-axis is treated as a date
        yaxis = list(title = "Volatility"),
        updatemenus = list(
            list(
                type = "buttons",
                active = -1,
                buttons = list(
                    list(label = "S&P 500",
                         method = "update",
                         args = list(list(visible = c(TRUE, FALSE, FALSE, FALSE)),
                                     list(title = "Volatility of the Raw S&P 500"))),
                    list(label = "CAC 40",
                         method = "update",
                         args = list(list(visible = c(FALSE, TRUE, FALSE, FALSE)),
                                     list(title = "Volatility of the Raw CAC 40"))),
                    list(label = "NASDAQ",
                         method = "update",
                         args = list(list(visible = c(FALSE, FALSE, TRUE, FALSE)),
                                     list(title = "Volatility of the Raw NASDAQ"))),
                    list(label = "Nikkei",
                         method = "update",
                         args = list(list(visible = c(FALSE, FALSE, FALSE, TRUE)),
                                     list(title = "Volatility of the Raw NIKKEI")))
                )
            )
        )
    )

# Display the plot
p

```

Volatility graphs indicate periods with significant spikes in volatility (ex: Nasdaq between 1999-2000), which challenges the assumption of homoscedasticity. This assumption---that the variance of the error term remains constant throughout the time series---is a foundational element of the Black-Scholes model. The presence of heteroscedasticity, where variance fluctuates over time, undermines the model's premises, since Black-Scholes requires stable volatility to accurately price options

Therefore, we will fit a GARCH model that addresses the issue of heteroscedasticity of the residuals.

### (f) Fit GARCH models to the negative log returns of each series with both standardised and skewed t-distributions, with order (1; 1), using the garchFit() function from the fGarch library. Assess the quality of the fit by evaluating the residuals.

```{r question 2f}
# Fit a GARCH(1,1) model with standard t-distribution to the log returns
garch_sp500_std <- garchFit(~garch(1, 1), data = log_returns_sp500$SP500, cond.dist = "std")
garch_cac40_std <- garchFit(~garch(1, 1), data = log_returns_cac40$CAC40, cond.dist = "std")
garch_NASDAQ_std <- garchFit(~garch(1, 1), data = log_returns_nasdaq$NASDAQ, cond.dist = "std")
garch_nikkei_std <- garchFit(~garch(1, 1), data = log_returns_nikkei$NIKKEI, cond.dist = "std")

# Fit a GARCH(1,1) model with skewed t-distribution to the log returns
garch_sp500_sstd <- garchFit(~garch(1, 1), data = log_returns_sp500$SP500, cond.dist = "sstd")
garch_cac40_sstd <- garchFit(~garch(1, 1), data = log_returns_cac40$CAC40, cond.dist = "sstd")
garch_NASDAQ_sstd <- garchFit(~garch(1, 1), data = log_returns_nasdaq$NASDAQ, cond.dist = "sstd")
garch_nikkei_sstd <- garchFit(~garch(1, 1), data = log_returns_nikkei$NIKKEI, cond.dist = "sstd")

# After fitting the models, evaluate the residuals:
# For standardized t-distribution
residuals_sp500_std <- residuals(garch_sp500_std, standardize = TRUE)
residuals_cac40_std <- residuals(garch_cac40_std, standardize = TRUE)
residuals_NASDAQ_std <- residuals(garch_NASDAQ_std, standardize = TRUE)
residuals_nikkei_std <- residuals(garch_nikkei_std, standardize = TRUE)

# For skewed t-distribution
residuals_sp500_sstd <- residuals(garch_sp500_sstd, standardize = TRUE)
residuals_cac40_sstd <- residuals(garch_cac40_sstd, standardize = TRUE)
residuals_NASDAQ_sstd <- residuals(garch_NASDAQ_sstd, standardize = TRUE)
residuals_nikkei_sstd <- residuals(garch_nikkei_sstd, standardize = TRUE)

# Plot the residuals and their ACF to assess quality
# Using plot
par(mfrow = c(2, 2))
plot(residuals_sp500_std, main="SP500")
plot(residuals_cac40_std, main="CAC40")
plot(residuals_NASDAQ_std, main="NASDAQ")
plot(residuals_nikkei_std, main="NIKKEI")
mtext("Residuals of Garch Model with standardized t-distribution", outer = TRUE, cex = 1, line = -1)
par(mfrow = c(2, 2))
acf(residuals_sp500_std^2, main="SP500")
acf(residuals_cac40_std^2, main="CAC40")
acf(residuals_NASDAQ_std^2, main="NASDAQ")
acf(residuals_nikkei_std^2, main="NIKKEI")
mtext("ACF of Squared Residuals with standardized t-distribution", outer = TRUE, cex = 1, line = -1)

# For skewed distribution
par(mfrow = c(2, 2))
plot(residuals_sp500_sstd, main="Residuals of SP500 GARCH Model with sstd t-dist")
plot(residuals_cac40_sstd, main="Residuals of CAC40 GARCH Model with sstd t-dist")
plot(residuals_NASDAQ_sstd, main="Residuals of NASDAQ GARCH Model with sstd t-dist")
plot(residuals_nikkei_sstd, main="Residuals of NIKKEI GARCH Model with sstd t-dist")
mtext("Residuals of Garch Model with skewed t-distribution", outer = TRUE, cex = 1, line = -1)
par(mfrow = c(2, 2))
acf(residuals_sp500_sstd^2, main="SP500")
acf(residuals_cac40_sstd^2, main="CAC40")
acf(residuals_NASDAQ_sstd^2, main="NASDAQ")
acf(residuals_nikkei_sstd^2, main="NIKKEI")
mtext("ACF of Squared Residuals with skewed t-distribution", outer = TRUE, cex = 1, line = -1)

# Perform Ljung-Box tests and collect the p-values
p_values_squared_residuals <- c(
  Box.test(residuals_sp500_std^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_sp500_sstd^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_cac40_std^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_cac40_sstd^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_NASDAQ_std^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_NASDAQ_sstd^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_nikkei_std^2, lag = 20, type = "Ljung-Box")$p.value,
  Box.test(residuals_nikkei_sstd^2, lag = 20, type = "Ljung-Box")$p.value
)

# Create a data frame with the results
ljung_box_results <- data.frame(
  Index = rep(c("SP500", "CAC40", "NASDAQ", "NIKKEI"), each = 2),
  Distribution = rep(c("STD", "SSTD"), times = 4),
  P_Value = p_values_squared_residuals
)

# Create a kable
kable_output <- kable(ljung_box_results, format = "html", caption = "Ljung-Box Test Results on Squared Residuals") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)

# Print the kable to the R console (note: this will not render as HTML in the console)
kable_output

```

Ho: data are independently distributed, implying that there is no autocorrelation among the values. H1: data exhibit some level of autocorrelation, meaning that past values in the series have a statistically significant influence on future values.

The quality of the fit is very poor as the null hypothesis is rejected, implying that the negative log return exhibit some level of autocorrelation.

```{r}
# Determining if the skewed t distribution is better than the standard t distribution
boxplot(residuals_sp500_std - residuals_sp500_sstd)
boxplot(residuals_cac40_std - residuals_cac40_sstd)
boxplot(residuals_NASDAQ_std - residuals_NASDAQ_sstd)
boxplot(residuals_nikkei_std - residuals_nikkei_sstd)

```

As we can see from these boxplots, the standard t distribution and the skewed t distribution are slightly different, but the difference is so minimal that even if the skewness is a significant parameter, it does not change the results in a significant manner. Therefore, we will proceed with the simpler model, which is the standard t distribution.

### (g) Residual serial correlation can be present when fitting a GARCH directly on the negative log returns.

```{r question 3g, include=FALSE}
# Step 1: Fit an ARMA model
# Using auto.arima to automatically select the best p, q
arma_sp500_fit <- auto.arima(log_returns_sp500)
arma_cac40_fit <- auto.arima(log_returns_cac40)
arma_NASDAQ_fit <- auto.arima(log_returns_nasdaq)
arma_nikkei_fit <- auto.arima(log_returns_nikkei)

# Extract the residuals
arma_sp500_residuals <- residuals(arma_sp500_fit)
arma_cac40_residuals <- residuals(arma_cac40_fit)
arma_NASDAQ_residuals <- residuals(arma_NASDAQ_fit)
arma_nikkei_residuals <- residuals(arma_nikkei_fit)
acf(arma_sp500_residuals)

# Assess the ARMA squared residuals
par(mfrow = c(2, 2))
acf(arma_sp500_residuals^2)
acf(arma_cac40_residuals^2)
acf(arma_NASDAQ_residuals^2)
acf(arma_nikkei_residuals^2)
```

```{r}
# Step 2: Fit a GARCH(1,1) model on the residuals of the ARMA model
garch_sp500_std <- garchFit(~garch(1, 1), data = arma_sp500_residuals, cond.dist = "std")
garch_cac40_std <- garchFit(~garch(1, 1), data = arma_cac40_residuals, cond.dist = "std")
garch_NASDAQ_std <- garchFit(~garch(1, 1), data = arma_NASDAQ_residuals, cond.dist = "std")
garch_nikkei_std <- garchFit(~garch(1, 1), data = arma_nikkei_residuals, cond.dist = "std")
```

```{r quality of fit}
# Step 3: Assess the quality of the fit
residuals_sp500_garch <- residuals(garch_sp500_std, standardize = TRUE)
residuals_cac40_garch <- residuals(garch_cac40_std, standardize = TRUE)
residuals_NASDAQ_garch <- residuals(garch_NASDAQ_std, standardize = TRUE)
residuals_nikkei_garch <- residuals(garch_nikkei_std, standardize = TRUE)

par(mfrow = c(2, 2))
plot(residuals_sp500_garch, main="SP500 residuals with std t-dist")
plot(residuals_cac40_garch, main="CAC40 residuals with std t-dist")
plot(residuals_NASDAQ_garch, main="NASDAQ residuals with std t-dist")
plot(residuals_nikkei_garch, main="NIKKEI residuals with std t-dist")

Box.test(residuals_sp500_garch, lag = 20, type = "Ljung-Box")
Box.test(residuals_cac40_garch, lag = 20, type = "Ljung-Box")
Box.test(residuals_NASDAQ_garch, lag = 20, type = "Ljung-Box")
Box.test(residuals_nikkei_garch, lag = 20, type = "Ljung-Box")

Box.test(residuals_sp500_garch^2, lag = 20, type = "Ljung-Box")
Box.test(residuals_cac40_garch^2, lag = 20, type = "Ljung-Box")
Box.test(residuals_NASDAQ_garch^2, lag = 20, type = "Ljung-Box")
Box.test(residuals_nikkei_garch^2, lag = 20, type = "Ljung-Box")

```

As we can see from the results of the Ljung-Box test on both the residuals and the squared residuals, we cannot reject the null hypothesis of autocorrelation being present in the residuals of the GARCH(1,1) model. As a result, we have a good quality fit wit a GARCH(1,1), though a bit weaker in the case of SP500.

### (h) Use the garchAuto.R script in order to fit a GARCH on the residuals of the ARMA(p,q) from (g). Assess the quality of the  t.

```{r}
# Auto GARCH formula
garchAutoTryFit = function(
    ll,
    data,
    trace=FALSE,
    forecast.length=1,
    with.forecast=TRUE,
    ic="AIC",
    garch.model="garch" )
{
  formula = as.formula( paste( sep="",
                               "~ arma(", ll$order[1], ",", ll$order[2], ")+",
                               garch.model,
                               "(", ll$order[3], ",", ll$order[4], ")" ) )
  fit = tryCatch( garchFit( formula=formula,
                            data=data,
                            trace=FALSE,
                            cond.dist=ll$dist ),
                  error=function( err ) TRUE,
                  warning=function( warn ) FALSE )
  
  pp = NULL
  
  if( !is.logical( fit ) ) {
    if( with.forecast ) {
      pp = tryCatch( predict( fit,
                              n.ahead=forecast.length,
                              doplot=FALSE ),
                     error=function( err ) FALSE,
                     warning=function( warn ) FALSE )
      if( is.logical( pp ) ) {
        fit = NULL
      }
    }
  } else {
    fit = NULL
  }
  
  if( trace ) {
    if( is.null( fit ) ) {
      cat( paste( sep="",
                  "   Analyzing (", ll$order[1], ",", ll$order[2],
                  ",", ll$order[3], ",", ll$order[4], ") with ",
                  ll$dist, " distribution done.",
                  "Bad model.\n" ) )
    } else {
      if( with.forecast ) {
        cat( paste( sep="",
                    "   Analyzing (", ll$order[1], ",", ll$order[2], ",",
                    ll$order[3], ",", ll$order[4], ") with ",
                    ll$dist, " distribution done.",
                    "Good model. ", ic, " = ", round(fit@fit$ics[[ic]],6),
                    ", forecast: ",
                    paste( collapse=",", round(pp[,1],4) ), "\n" ) )
      } else {
        cat( paste( sep="",
                    "   Analyzing (", ll[1], ",", ll[2], ",", ll[3], ",", ll[4], ") with ",
                    ll$dist, " distribution done.",
                    "Good model. ", ic, " = ", round(fit@fit$ics[[ic]],6), "\n" ) )
      }
    }
  }
  
  return( fit )
}

garchAuto = function(
    xx,
    min.order=c(0,0,1,1),
    max.order=c(5,5,1,1),
    trace=FALSE,
    cond.dists="sged",
    with.forecast=TRUE,
    forecast.length=1,
    arma.sum=c(0,1e9),
    cores=1,
    ic="AIC",
    garch.model="garch" )
{
  require( fGarch )
  require( parallel )
  
  len = NROW( xx )
  
  models = list( )
  
  for( dist in cond.dists )
    for( p in min.order[1]:max.order[1] )
      for( q in min.order[2]:max.order[2] )
        for( r in min.order[3]:max.order[3] )
          for( s in min.order[4]:max.order[4] )
          {
            pq.sum = p + q
            if( pq.sum <= arma.sum[2] && pq.sum >= arma.sum[1] )
            {
              models[[length( models ) + 1]] = list( order=c( p, q, r, s ), dist=dist )
            }
          }
  
  res = mclapply( models,
                  garchAutoTryFit,
                  data=xx,
                  trace=trace,
                  ic=ic,
                  garch.model=garch.model,
                  forecast.length=forecast.length,
                  with.forecast=TRUE,
                  mc.cores=cores )
  
  best.fit = NULL
  
  best.ic = 1e9
  for( rr in res )
  {
    if( !is.null( rr ) )
    {
      current.ic = rr@fit$ics[[ic]]
      if( current.ic < best.ic )
      {
        best.ic = current.ic
        best.fit = rr
      }
    }
  }
  
  if( best.ic < 1e9 )
  {
    return( best.fit )
  }
  
  return( NULL )
}
```

```{r}
#Fit the AutoGarch on the ARMA residuals
autogarch_sp500_std <- garchAuto(arma_sp500_residuals)
autogarch_cac40_std <- garchAuto(arma_cac40_residuals)
autogarch_NASDAQ_std <- garchAuto(arma_NASDAQ_residuals)
autogarch_nikkei_std <- garchAuto(arma_nikkei_residuals)

#Get the standardized residuals of the AutoGarch
residuals_sp500_autogarch <- residuals(autogarch_sp500_std, standardize = TRUE)
residuals_cac40_autogarch <- residuals(autogarch_cac40_std, standardize = TRUE)
residuals_NASDAQ_autogarch <- residuals(autogarch_NASDAQ_std, standardize = TRUE)
residuals_nikkei_autogarch <- residuals(autogarch_nikkei_std, standardize = TRUE)

par(mfrow = c(2, 2))
plot(residuals_sp500_autogarch, main="SP500 residuals with std t-dist")
plot(residuals_cac40_autogarch, main="CAC40 residuals with std t-dist")
plot(residuals_NASDAQ_autogarch, main="NASDAQ residuals with std t-dist")
plot(residuals_nikkei_autogarch, main="NIKKEI residuals with std t-dist")

#Assess the quality of the fit
Box.test(residuals_sp500_autogarch, lag = 20, type = "Ljung-Box")
Box.test(residuals_cac40_autogarch, lag = 20, type = "Ljung-Box")
Box.test(residuals_NASDAQ_autogarch, lag = 20, type = "Ljung-Box")
Box.test(residuals_nikkei_autogarch, lag = 20, type = "Ljung-Box")

Box.test(residuals_sp500_autogarch^2, lag = 20, type = "Ljung-Box")
Box.test(residuals_cac40_autogarch^2, lag = 20, type = "Ljung-Box")
Box.test(residuals_NASDAQ_autogarch^2, lag = 20, type = "Ljung-Box")
Box.test(residuals_nikkei_autogarch^2, lag = 20, type = "Ljung-Box")


```

The results of the Ljung Box tests on the autoGarch function residuals give us non-significant p-values as well, except for the SP500. This means that we cannot reject the null hypothesis of autocorrelation between the residuals for CAC40, NASDAQ and Nikkei, but we do reject it at a 95% confidence level for SP500. However, the squared residuals for SP500 show a high enough p-value for it to not be rejected.

We can conclude that SP500 could still have autocorrelation in its residuals, but it depends on which Ljung-Box test we decide to trust more (normal residuals or squared residuals).
